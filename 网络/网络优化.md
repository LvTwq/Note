[toc]

# 优化目标

具体到不同应用中，每个指标的优化标准不同。

* NAT 网关：影响整个数据中心的网络出入性能，PPS（吞吐量）是主要目标，要等达到线性转发
* 数据库、缓存：快速完成网络收发，即低延迟
* Web 服务：吞吐量和延迟

![img](..\images\网络优化01.jpg)

* 网络接口层和网络层：主要负责网络包的封装、寻址、路由，以及发送和接收。每秒可处理的网络包PPS，就是最重要的性能指标。可以使用 pktgen，来测试
* 传输层：主要负责网络传输。吞吐量（BPS）、连接数以及延迟，就是最重要的性能指标。可以用 iperf 或 netperf，来测试
* 应用层：最需要关注的是吞吐量（BPS）、每秒请求数以及延迟等指标。可以用 wrk、ab 等工具，来测试应用程序的性能

# 工具

![img](..\images\网络优化02.jpg)

![img](..\images\网络优化03.jpg)

# 性能优化

![img](..\images\网络优化04.jpg)

## 应用程序

应用程序，通常通过 `套接字`进行网络操作。由于网络收发通常比较耗时，所以应用程序的优化，主要就是对网络 I/O 和进程自身的工作模型的优化。

从网络 I/O 的角度来说，主要有下面两种优化思路：

* I/O 多路复用 epoll，主要用来取代 select 和 poll。
* 异步 I/O

从进程的工作模型来说，有两种：

* 主进程+多个worker子进程。其中，主进程负责管理网络链接，子进程负责实际的业务处理
* 监听相同端口的多进程模型。所有进程都会监听相同接口，并且开启 SO_REUSEPORT 选项，由内核负责，把请求负载均衡到这些监听进程中去

除此之外，应用层的**网络协议优化**，也是至关重要的一点：

* 使用长连接取代短连接，可以显著降低 TCP 建立连接的成本。在每秒请求次数多的时候，效果明显
* 使用内存，缓存不常变化的数据，降低网络 I/O 次数
* 使用 Protocol Buffer 等序列化的方式，压缩网络 I/O 的数据量
* 使用 DNS 缓存、预取、HTTPDNS 等方式，减少 DNS 解析的延迟，也可以提升网络 I/O 的整体速度

## 套接字

套接字可以屏蔽掉 Linux 内核中不同协议的差异，为应用程序提供统一的访问接口。每个套接字，都有一个读写缓冲区

* 读缓冲区，缓存了远端发过来的数据。如果读缓冲区已满，就不能再接收新的数据
* 写缓冲区，缓存要发出去的数据，如果写缓冲区已满，应用程序的写操作就会被阻塞

所以，为了提高网络的吞吐量，需要调整这些缓冲区的大小：

* 增大每个套接字的缓冲区大小 net.core.optmem_max
* 增大套接字接收缓冲区大小 net.core.rmem_max 和发送缓冲区大小 net.core.wmem_max
* 增大 TCP 接收缓冲区大小 net.ipv4.tcp_rmem 和发送缓冲区大小 net.ipv4.tcp_wmem

## 传输层

![img](..\images\网络优化05.jpg)

### 请求数较大场景

可能会有大量处于 TIME_WAIT 状态的连接，它们会占用大量内存和端口资源，

* 增大处于 TIME_WAIT 状态的连接数量 net.ipv4.tcp_max_tw_buckets ，并增大连接跟踪表的大小 net.netfilter.nf_conntrack_max
* 减小 net.ipv4.tcp_fin_timeout 和 net.netfilter.nf_conntrack_tcp_timeout_time_wait ，让系统尽快释放它们所占用的资源
* 开启端口复用 net.ipv4.tcp_tw_reuse。这样，被 TIME_WAIT 状态占用的端口，还能用到新建的连接中
* 增大本地端口的范围 net.ipv4.ip_local_port_range 。这样就可以支持更多连接，提高整体的并发能力
* 增加最大文件描述符的数量。你可以使用 fs.nr_open 和 fs.file-max ，分别增大进程和系统的最大文件描述符数；或在应用程序的 systemd 配置文件中，配置 LimitNOFILE ，设置应用程序的最大文件描述符数

### 洪水攻击

为了缓解 SYN FLOOD 等，利用 TCP 协议特点进行攻击而引发的性能问题，你可以考虑优化与 SYN 状态相关的内核选项

* 增大 TCP 半连接的最大数量 net.ipv4.tcp_max_syn_backlog ，或者开启 TCP SYN Cookies net.ipv4.tcp_syncookies ，来绕开半连接数量限制的问题（注意，这两个选项不可同时使用）
* 减少 SYN_RECV 状态的连接重传 SYN+ACK 包的次数 net.ipv4.tcp_synack_retries


### 长连接

在长连接的场景中，通常使用 Keepalive 来检测 TCP 连接的状态，以便对端连接断开后，可以自动回收。但是，系统默认的 Keepalive 探测间隔和重试次数，一般都无法满足应用程序的性能要求。所以，这时候你需要优化与 Keepalive 相关的内核选项

* 缩短最后一次数据包到 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_time
* 缩短发送 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_intvl
* 减少Keepalive 探测失败后，一直到通知应用程序前的重试次数 net.ipv4.tcp_keepalive_probes

![img](..\images\网络优化06.jpg)


## 网络层

网络层，负责网络包的封装、寻址、路由，包括 IP、ICMP 等常见协议。在网络层，最主要的优化，其实就是对路由、IP 分片以及 ICMP 等进行调优。

### 从路由和转发的角度出发

* 在需要转发的服务器中，比如用作 NAT 网关的服务器或者使用 docker 容器时，开启 IP 转发，即设置 net.ipv4.ip_forward = 1
* 调整数据包的生存周期 TTL，比如设置 net.ipv4.ip_default_ttl = 64。注意，增大该值会降低系统性能
* 开启数据包的反向地址校验，比如设置 net.ipv4.conf.eth0.rp_filter = 1。这样可以防止 IP 欺骗，并减少伪造 IP 带来的 DDoS 问题


### 从分片角度

调整 MTU（Maximum Transmission Unit）的大小

通常，MTU 的大小应该根据以太网的标准来设置。以太网标准规定，一个网络帧最大为 1518B，那么去掉以太网头部的 18B 后，剩余的 1500 就是以太网 MTU 的大小


### 从 ICMP 角度

为了避免 ICMP 主机探测、ICMP Flood 等各种网络问题，你可以通过内核选项，来限制 ICMP 的行为

* 可以禁止 ICMP 协议，即设置 net.ipv4.icmp_echo_ignore_all = 1。这样，外部主机就无法通过 ICMP 来探测主机
* 还可以禁止广播 ICMP，即设置 net.ipv4.icmp_echo_ignore_broadcasts = 1


## 链路层



# 如何解决丢包问题

![img](..\images\网络优化07.jpg)

所谓丢包，是指网络数据在收发过程中，由于种种原因，数据包还没传输到应用程序中，就被丢弃了。这些被丢弃包的数量/总的传输包数，也就是**丢包率**。

丢包通常会带来严重的性能下降，特别是对 TCP 来说，丢包通常意味着网络拥塞和重传，进而还会导致网络延迟增大、吞吐降低。

```bash
# -c表示发送10个请求，-S表示使用TCP SYN，-p指定端口为80
$ hping3 -c 10 -S -p 80 192.168.0.30
HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes
len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=3 win=5120 rtt=7.5 ms
len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=4 win=5120 rtt=7.4 ms
len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=5 win=5120 rtt=3.3 ms
len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=7 win=5120 rtt=3.0 ms
len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=6 win=5120 rtt=3027.2 ms

--- 192.168.0.30 hping statistic ---
10 packets transmitted, 5 packets received, 50% packet loss
round-trip min/avg/max = 3.0/609.7/3027.2 ms
```

从 hping3 的输出中，我们可以发现，发送了 10 个请求包，却只收到了 5 个回复，50% 的包都丢了。再观察每个请求的 RTT 可以发现，RTT 也有非常大的波动变化，小的时候只有 3ms，而大的时候则有 3s

## 链路层

当缓冲区溢出等原因导致网卡丢包时，Linux 会在网卡收发数据的统计信息中，记录下收发错误的次数。

```shell
root@nginx:/# netstat -i
Kernel Interface table
Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
eth0       100       31      0      0 0             8      0      0      0 BMRU
lo       65536        0      0      0 0             0      0      0      0 LRU
```

输出中的 RX-OK、RX-ERR、RX-DRP、RX-OVR ，分别表示接收时的总包数、总错误数、进入Ring Buffer 后因其他原因（如内存不足）导致的丢包数以及 Ring Buffer 溢出导致的丢包数。


## 网络层和传输层

```bash
root@nginx:/# netstat -s
Ip:
    Forwarding: 1					//开启转发
    31 total packets received		//总收包数
    0 forwarded						//转发包数
    0 incoming packets discarded	//接收丢包数
    25 incoming packets delivered	//接收的数据包数
    15 requests sent out			//发出的数据包数
Icmp:
    0 ICMP messages received		//收到的ICMP包数
    0 input ICMP message failed		//收到ICMP失败数
    ICMP input histogram:
    0 ICMP messages sent			//ICMP发送数
    0 ICMP messages failed			//ICMP失败数
    ICMP output histogram:
Tcp:
    0 active connection openings	//主动连接数
    0 passive connection openings	//被动连接数
    11 failed connection attempts	//失败连接尝试数
    0 connection resets received	//接收的连接重置数
    0 connections established		//建立连接数
    25 segments received			//已接收报文数
    21 segments sent out			//已发送报文数
    4 segments retransmitted		//重传报文数
    0 bad segments received			//错误报文数
    0 resets sent					//发出的连接重置数
Udp:
    0 packets received
    ...
TcpExt:
    11 resets received for embryonic SYN_RECV sockets	//半连接重置数
    0 packet headers predicted
    TCPTimeouts: 7		//超时数
    TCPSynRetrans: 4	//SYN重传数
	...
```

netstat 汇总了 IP、ICMP、TCP、UDP 等协议的收发统计信息，根据上面的输出，可以看到，只有 TCP 协议发生了丢包和重传：

* 11 次连接失败重试（11 failed connection attempts）
* 4 次重传（4 segments retransmitted）
* 11 次半连接重置（11 resets received for embryonic SYN_RECV sockets）
* 4 次 SYN 重传（TCPSynRetrans）
* 7 次超时（TCPTimeout）

最多的错误是半连接重置。换句话说，主要的失败，都是三次握手失败。


## iptables

直接查询 DROP 和 REJECT 等规则的统计信息，看看是否为 0。如果统计值不是 0 ，再把相关的规则拎出来进行分析

```bash
# iptables -t filter -nvL
Chain INPUT (policy ACCEPT 25 packets, 1000 bytes)
 pkts bytes target     prot opt in     out     source               destination
    6   240 DROP       all  --  *      *       0.0.0.0/0            0.0.0.0/0            statistic mode random probability 0.29999999981

Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 15 packets, 660 bytes)
 pkts bytes target     prot opt in     out     source               destination
    6   264 DROP       all  --  *      *       0.0.0.0/0            0.0.0.0/0            statistic mode random probability 0.29999999981
```

两条 DROP 规则的统计数值不是 0，它们分别在 INPUT 和 OUTPUT 链中，使用 statistic 模块，进行随机 30% 的丢包



## tcpdump

```bash
$ curl --max-time 3 http://192.168.0.30/
curl: (28) Operation timed out after 3000 milliseconds with 0 bytes received
```


```bash
# tcpdump -i eth0 -nn port 80


14:40:00.589235 IP 10.255.255.5.39058 > 172.17.0.2.80: Flags [S], seq 332257715, win 29200, options [mss 1418,sackOK,TS val 486800541 ecr 0,nop,wscale 7], length 0
14:40:00.589277 IP 172.17.0.2.80 > 10.255.255.5.39058: Flags [S.], seq 1630206251, ack 332257716, win 4880, options [mss 256,sackOK,TS val 2509376001 ecr 486800541,nop,wscale 7], length 0
14:40:00.589894 IP 10.255.255.5.39058 > 172.17.0.2.80: Flags [.], ack 1, win 229, options [nop,nop,TS val 486800541 ecr 2509376001], length 0
14:40:03.589352 IP 10.255.255.5.39058 > 172.17.0.2.80: Flags [F.], seq 76, ack 1, win 229, options [nop,nop,TS val 486803541 ecr 2509376001], length 0
14:40:03.589417 IP 172.17.0.2.80 > 10.255.255.5.39058: Flags [.], ack 1, win 40, options [nop,nop,TS val 2509379001 ecr 486800541,nop,nop,sack 1 {76:77}], length 0
```

从 tcpdump 的输出中，我们就可以看到：

* 前三个包是正常的 TCP 三次握手，这没问题
* 但第四个包却是在 3 秒以后了，并且还是客户端（VM2）发送过来的 **FIN 包**，也就说明，**客户端的连接关闭了**

根据 curl 设置的 3 秒超时选项，这是因为 curl 命令超时后退出了，用 Wireshark 的 Flow Graph 表示

![img](..\images\网络优化08.jpg)

这里比较奇怪的是，我们并没有抓取到 curl 发来的 HTTP GET 请求。那么，究竟是网卡丢包了，还是客户端压根儿就没发过来呢？

可以重新执行 netstat -i 命令，确认一下网卡有没有丢包问题：

```bash
# netstat -i
Kernel Interface table
Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
eth0       100      157      0    344 0            94      0      0      0 BMRU
lo       65536        0      0      0 0             0      0      0      0 LRU
```

接收丢包数（RX-DRP）是 344，果然是在网卡接收时丢包了。不过问题也来了，为什么刚才用 hping3 时不丢包，现在换成 GET 就收不到了呢？

* hping3 实际上只发送了 SYN 包；
* 而 curl 在发送 SYN 包后，还会发送 HTTP GET 请求。

HTTP GET，本质上也是一个 TCP 包；但是携带了 HTTP GET 数据。那有可能是 MTU 配置错误导致的。

上面 netstat 的输出界面，第二列正是每个网卡的 MTU 值。eth0 的 MTU 只有 100，而以太网的 MTU 默认值是 1500，这个100 就显得太小了
