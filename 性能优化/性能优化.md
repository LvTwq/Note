# 从一个**包含上百万用户**的列表中，根据用户输入的关键词（如用户名、邮箱）进行 **模糊搜索** 。目前的实现是简单的 `LIKE '%keyword%'` 数据库查询，如何优化

## 问题所在

全表扫描

## 分层优化策略

### 利用数据库索引（场景化）

* 如果主要是 **前缀搜索** （如搜索 `zhang%`），确保 `username`/`email` 有索引，`LIKE 'keyword%'` 会走索引。
* 如果是 **后缀搜索** （如 `@gmail.com`），可以考虑存储一个 `email_reversed` 字段，并为其建立索引，将后缀查询转化为前缀查询。

### 引入es

ES 基于 **倒排索引** ，天生为搜索而生。

将用户数据（ID, username, email）通过 `Logstash` 或业务代码中的 `Kafka Producer` 同步到 ES。搜索时，使用 ES 的 `match` 或 `wildcard` 查询（甚至 `fuzzy` 模糊匹配），能在毫秒内返回结果。

### 算法和数据结构辅助

* **搜索建议（AutoComplete）** ：如果需要输入提示，我会用  **Trie 树** 。将所有用户名构建成 Trie 树，缓存在内存或 Redis 中，实现亚毫秒级的前缀搜索建议。
* **无效查询过滤** ：对于明显无效的搜索词（如随机字符串），可以先用 **布隆过滤器** 快速判断其是否可能存在于我们的数据中，避免不必要的后端查询。

### 缓存

* **热点缓存** ：将最常搜索的 Top N 结果（如 "admin"）缓存在 Redis。
* **异步更新** ：用户数据变更时，通过 Kafka 异步更新 ES 索引，保证最终一致性，不影响核心业务。

# 假设我们有一个按时间排序的用户登录日志流，每条日志包含 `user_id` 和 `login_timestamp`（时间戳）

> 请设计一个算法，能够**实时地**检测出“ **异常高频登录行为** ”。我们定义：如果某个用户在 **任意连续的 5 分钟（300秒）时间窗口内，登录次数超过 10 次** ，则认为该用户存在异常高频登录风险，需要触发告警。
>
> **要求：**
>
> 1. 算法需要支持 **实时处理** （日志是持续到来的）。
> 2. 考虑到用户量巨大，算法需要 **高效** ，不能对每个新日志都扫描所有历史日志。

思路：使用 **“双端队列（Deque）”** 结合 **“延迟清理”** 的策略来解决。为每个用户维护一个双端队列，只存储其最近5分钟内的登录时间戳。

处理流程：

* 清理：对于每个新登录事件，先移除队列中所有早于5分钟前的旧纪录。
* 添加：将当前登录时间戳加入队列尾部
* 判断：检查队列长度是否超过10

均摊时间复杂度 O(1)，只处理有效数据
